{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a804783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae1e86d",
   "metadata": {},
   "source": [
    "# Mimic sklearn\n",
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409a8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X): \n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        for c in X.columns:\n",
    "            if is_numeric_dtype(X[c]):\n",
    "                u = np.mean(X[c])\n",
    "                s = np.std(X[c])\n",
    "                X[c] = (X[c] - u) / s\n",
    "        return\n",
    "    \n",
    "    for j in range(X.shape[1]):\n",
    "        u = np.mean(X[:,j])\n",
    "        s = np.std(X[:,j])\n",
    "        X[:,j] = (X[:,j] - u) / s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8f214",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a0eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(X,y,B,lmbda):\n",
    "    \"\"\"\n",
    "    X, y, B are all numpy arrays\n",
    "    X: (n, p) Matrix\n",
    "    Y: (n, 1) vector\n",
    "    B: (p, 1) coefficient vector\n",
    "    In the final equation, we don’t care about scaling MSE by 1/n\n",
    "    \"\"\"\n",
    "    dif = y - np.dot(X,B)\n",
    "    return np.multiply(dif, dif)\n",
    "\n",
    "\n",
    "def loss_gradient(X, y, B, lmbda):\n",
    "    dif = y - np.dot(X,B)\n",
    "    return -np.dot(np.transpose(X),dif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5155324d",
   "metadata": {},
   "source": [
    "**Adagrad Minimize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c779ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize(X, y, loss, loss_gradient,\n",
    "             eta=0.00001, lmbda=0.0,\n",
    "             max_iter=1000, addB0=True,\n",
    "             precision=0.00000001):\n",
    "    \"\"\"\n",
    "    eta: learning rate\n",
    "    addB0: dictates whether or not to use augmented vectors and matrices. \n",
    "           We always set addB0=True except for regularizations, \n",
    "           which compute β0 outside of the minimization process (as just y) assuming standardized variables.\n",
    "    \"\"\"\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(\"X must be n x p for p features\")\n",
    "    n, p = X.shape\n",
    "    if y.shape != (n, 1):\n",
    "        raise ValueError(f\"y must be n={n} x 1 not {y.shape}\")\n",
    "\n",
    "    B = np.random.random_sample(size=(p, 1)) * 2 - 1\n",
    "    h = np.zeros(shape=(p,1))\n",
    "    if addB0:\n",
    "        n = X.shape[0]\n",
    "        B0 = np.ones(shape=(n,1))\n",
    "        X = np.hstack([B0, X]) # add column of 1s to X\n",
    "        B = np.random.random_sample(size=(p+1, 1)) * 2 - 1  # make between [-1,1) \n",
    "        h = np.zeros(shape=(p+1,1))\n",
    "\n",
    "    prev_B = B \n",
    "    step = 0\n",
    "    eps = 1e-5 # prevent division by 0\n",
    "    norm = np.linalg.norm(loss_gradient(X, y, B, lmbda))\n",
    "    while step <= max_iter and norm > precision:\n",
    "        cur_grad = loss_gradient(X, y, B, lmbda) \n",
    "        h += cur_grad * cur_grad\n",
    "        B -= eta * cur_grad/(np.sqrt(h)+eps)\n",
    "        step += 1\n",
    "        norm = np.linalg.norm(loss_gradient(X, y, B, lmbda))\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7146b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression_new: \n",
    "    def __init__(self, \n",
    "                 eta=0.00001, \n",
    "                 lmbda=0.0, \n",
    "                 max_iter=1000):\n",
    "        self.eta = eta\n",
    "        self.lmbda = lmbda\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.B = minimize(X, y,\n",
    "                           MSE,\n",
    "                           loss_gradient,\n",
    "                           self.eta,\n",
    "                           self.lmbda,\n",
    "                           self.max_iter)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        n = X.shape[0]\n",
    "        B0 = np.ones(shape=(n, 1))\n",
    "        X = np.hstack([B0, X])\n",
    "        return np.dot(X, self.B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b0517",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6841ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_ridge(X, y, B, lmbda):\n",
    "    \"\"\"\n",
    "    Loss function for L2 regularization.\n",
    "    We don’t care about scaling.\n",
    "    \"\"\"\n",
    "    dif = y - np.dot(X,B)\n",
    "    return np.multiply(dif,dif)+lmbda*np.multiply(B,B)\n",
    "\n",
    "\n",
    "def loss_gradient_ridge(X, y, B, lmbda):\n",
    "    dif = y - np.dot(X,B)\n",
    "    return (-np.dot(np.transpose(X),dif)+lmbda*B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa4151c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression_new: \n",
    "    def __init__(self,\n",
    "                 eta=0.00001, lmbda=0.0,\n",
    "                 max_iter=1000,addB0=False):\n",
    "        self.eta = eta\n",
    "        self.lmbda = lmbda\n",
    "        self.max_iter = max_iter\n",
    "        self.addB0 = addB0\n",
    "\n",
    "    def predict(self, X):\n",
    "        n = X.shape[0]\n",
    "        B0 = np.ones(shape=(n, 1))\n",
    "        X = np.hstack([B0, X])\n",
    "        return np.dot(X, self.B)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        Bs = minimize(X, y,\n",
    "                        loss_ridge,\n",
    "                        loss_gradient_ridge,\n",
    "                        self.eta,\n",
    "                        self.lmbda,\n",
    "                        self.max_iter,\n",
    "                        self.addB0)\n",
    "        B0 = np.mean(y)\n",
    "        self.B = np.insert(Bs,0,B0).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeccb286",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1af273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "\n",
    "def log_likelihood(X, y, B,lmbda):\n",
    "    term1 = sum(y*X) * B\n",
    "    n = X.shape[0]\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += np.log(1+np.exp(np.dot(X[i,:],B)))\n",
    "    return (-term1+s)\n",
    "\n",
    "\n",
    "def log_likelihood_gradient(X, y, B, lmbda):\n",
    "    dif = y - sigmoid(np.dot(X,B))\n",
    "    return (-np.dot(np.transpose(X),dif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed76ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression_new: \n",
    "    def __init__(self,\n",
    "                 eta=0.00001, lmbda=0.0,\n",
    "                 max_iter=1000):\n",
    "        self.eta = eta\n",
    "        self.lmbda = lmbda\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.B = minimize(X, y,\n",
    "                           log_likelihood,\n",
    "                           log_likelihood_gradient,\n",
    "                           self.eta,\n",
    "                           self.lmbda,\n",
    "                           self.max_iter)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Compute the probability that the target is 1. \n",
    "        Do the usual linear regression and then pass through a sigmoid.\n",
    "        \"\"\"\n",
    "        n = X.shape[0]\n",
    "        B0 = np.ones(shape=(n, 1))\n",
    "        X = np.hstack([B0, X])\n",
    "        prob = sigmoid(np.dot(X,self.B))\n",
    "        return prob\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Call self.predict_proba() to get probabilities then, for each x in X,\n",
    "        return a 1 if P(y==1,x) > 0.5 else 0.\n",
    "        \"\"\"     \n",
    "        prob = self.predict_proba(X)\n",
    "        def prob_p(x):\n",
    "            if x > 0.5:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        pred = np.array(list(map(prob_p,prob)))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77820d0",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6adc5c",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "191bac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a45d4fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 1), (506, 13))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target.reshape(-1, 1)\n",
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7636aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb8e82ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2 0.7022974023993411\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression_new(max_iter=30000, eta=5)\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"r^2\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f39013",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34cbaabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2 0.6573106705493537\n"
     ]
    }
   ],
   "source": [
    "l2r = RidgeRegression_new(max_iter=30000, eta=5, lmbda=80)\n",
    "l2r.fit(X_train,y_train)\n",
    "y_pred = l2r.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"r^2\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e484dca",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "598780ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 1), (569, 30))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from test_class import *\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target.reshape(-1,1)\n",
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eda81837",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04b34faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression_new(max_iter=30000, eta=5,)\n",
    "logreg.fit(X_train,y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('accuracy:',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83fbc4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000],\n",
       "       [5.71988721e-081],\n",
       "       [2.76402440e-008],\n",
       "       [2.27488510e-111],\n",
       "       [1.00000000e+000],\n",
       "       [9.95356113e-001],\n",
       "       [1.00000000e+000],\n",
       "       [6.34253990e-110],\n",
       "       [1.00000000e+000],\n",
       "       [1.27296053e-027],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [4.63218756e-086],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [5.90528248e-043],\n",
       "       [1.44078087e-038],\n",
       "       [1.00000000e+000],\n",
       "       [2.40972862e-003],\n",
       "       [1.86526911e-029],\n",
       "       [9.99999746e-001],\n",
       "       [1.08772275e-046],\n",
       "       [1.34301912e-024],\n",
       "       [4.48788480e-121],\n",
       "       [1.00000000e+000],\n",
       "       [1.67713689e-001],\n",
       "       [1.50684610e-108],\n",
       "       [9.61564896e-033],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [4.29697181e-018],\n",
       "       [9.99999995e-001],\n",
       "       [1.00000000e+000],\n",
       "       [4.22779378e-039],\n",
       "       [1.05462376e-004],\n",
       "       [4.05852060e-022],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [2.11483410e-033],\n",
       "       [1.09229007e-091],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [9.35021876e-055],\n",
       "       [1.00000000e+000],\n",
       "       [2.60341706e-074],\n",
       "       [1.00000000e+000],\n",
       "       [9.99964680e-001],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [1.44675806e-001],\n",
       "       [1.00000000e+000],\n",
       "       [1.29280438e-051],\n",
       "       [9.99995630e-001],\n",
       "       [9.99794817e-001],\n",
       "       [1.18224172e-031],\n",
       "       [1.23486647e-044],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [3.25541697e-018],\n",
       "       [2.00610079e-114],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [1.73054644e-007],\n",
       "       [1.00000000e+000],\n",
       "       [9.99844390e-001],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [1.14561719e-068],\n",
       "       [1.00000000e+000],\n",
       "       [2.26659573e-046],\n",
       "       [1.00000000e+000],\n",
       "       [1.54916385e-133],\n",
       "       [2.30415763e-043],\n",
       "       [1.00000000e+000],\n",
       "       [7.79601248e-053],\n",
       "       [2.01066966e-004],\n",
       "       [9.99999998e-001],\n",
       "       [4.64050762e-002],\n",
       "       [1.00000000e+000],\n",
       "       [5.90393328e-048],\n",
       "       [2.47867239e-031],\n",
       "       [1.00000000e+000],\n",
       "       [3.00591207e-032],\n",
       "       [1.24765908e-067],\n",
       "       [1.00000000e+000],\n",
       "       [2.83954871e-021],\n",
       "       [9.99999999e-001],\n",
       "       [1.00000000e+000],\n",
       "       [3.26036948e-050],\n",
       "       [3.37250884e-030],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [6.35538326e-059],\n",
       "       [1.00000000e+000],\n",
       "       [5.42543268e-021],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000],\n",
       "       [6.58378616e-028],\n",
       "       [3.63674173e-089],\n",
       "       [9.62641665e-045],\n",
       "       [1.00000000e+000],\n",
       "       [2.12865407e-038],\n",
       "       [1.00000000e+000],\n",
       "       [2.22023259e-009],\n",
       "       [1.00000000e+000],\n",
       "       [1.00000000e+000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3cba675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
